# I. Запуск контейнера

## 1. Уапоковка образа
`docker build -t cbr-hw-dockerization .`

## 2. Запук контейнера
`docker run -t -i -p 5000:5000 cbr-hw-dockerization`

# II. Замечание по работе проекта
Иногда сайт Росстата не отвечает и проект выдает ошибку (отсутствие ответа от сервера). В таких случаях нужно запустить проект ещё раз, если сайт не лежит, то код отработает.

# III. Состав проекта
1. requirements.txt - файл со списком необходимых пакетов и версий для проекта
2. func.py - файл со вспомогательными функциями загрузки и обработки данных
3. plot.py - файл с функцией прогноза и построение графика ИПЦ
4. app.py - файл со скриптом запуска сайта через flask
5. Dockerfile - файл с командой запуска докера
6. templates/ipc_fcs.html - файл с HTML кодом web страницы
7. static/images/plot.png - сохраненный файл после отработки app.py
8. research/ipc_research.py - файл с небольшим исследованием данных
В файлах основного кода (*.py) содержатся краткие комментарии по ходу программы

# IV. Исследование
## 1. Список данных
a. ИПЦ месяц к месяцу - обязательный ряд, который нужно прогнозировать (исочник - Росстат)

б. Денежная масса M2 млрд руб - влияет на ИПЦ в монетарных моделях (источник - Банк России)

в. Курс рубля к доллару - среднемесячное значение (источник - Банк России). Влияет на ИПЦ, т.к. от него завяисят импортные цены

Также рассматривалась возможность добавления ряда уровня безработицы, как основной показатель в модели Филлипса, и реальных денежных доходов населения, как основной драйвер потребления, который разгоняет инфляцию. Но данные ряды были представлены в открытых источниках в коротких вариантах и с низкой частостой (квартальной).

## 2. Список преобразований
а. Курс рубля и денежная масса брались в приростах. Мотивация: ИПЦ - тоже "прирост" цен;
если будет прогноз с помощью эконометрических моделей, то необходима интегрированность рядов одного порядка (все ряды тестировались ADF-ом, результаты в research/ipc_research.py);
если будет прогноз с помощью моделей машинного обучения, то такое преобразование ускорит сходимость.

б. Данные "подстригались" по 1% и 99% квантилям. Такой подход убирает спайки в данных, которые нет смысла (и возможности) предсказывать - это недетерминированные структурные сдвиги.

в. Данные обрезлись с начала 2000 года (в 90-х очень много спайков и нестабильных периодов в рядах).

Итоговые графики после первых трёх преобразований:

![image](https://github.com/hraparovna/CBR_HW/assets/78476837/caeafebb-fb7a-4a60-92f1-2e846757f41a)

![image](https://github.com/hraparovna/CBR_HW/assets/78476837/a6af1f86-4fb8-4c90-afd8-c7b60f8ed96a)

![image](https://github.com/hraparovna/CBR_HW/assets/78476837/be83626c-4e04-4839-b5c1-05f42b354084)


в. Доставались временные фичи - год и месяц.

г. Было принято решение использовать Градиентный бустинг (ради интереса). Выбор модели не участвовал в отборе на валидации, т.к. это существенно увеличило бы время анализа.

д. Брались лаги переменных с 6 по 8 для всех переменных, с 1 по 6 для переменных года и месяца (как предопределенных перменных). Таргет был мультизначным, было принято решение прогнозировать сразу 6 значений ИПЦ наперед. Набор лагов был выбран детерменированным и не участвовал в GridSearch на валидации, т.к. это существенно увеличило бы время анализа.

е. Объясняющие переменные прогонялись через модель изолирующего леса для детектирования выбросов. 

## 3. Модель и отбор гиперпараметров.
а. В качестве исходной модели был выбран градиентный бустинг с мультизначным выходом и квантильной метрикой, т.к. такой подход прогнозирует более стабильные значения ряда.

б. Гиперпараметры отбирались с помощью GridSearch и оценкой прогноза модели скользящим расширяющимся окном на валидационном множестве (с 01.2018). Метрика отбора - mean_absolute_error.

в. Итоговые гиперпараметры хардкодом были занесены в основной проект. Оставлять GridSearch в основном проекте не имеет смысла, т.к. необходима отработка проекта за разумное время.
Среди моделей можно было бы еще рассмотреть: SARIMA классы моделей, модели коинтеграции (в случае преобразования ИПЦ в накопительный, чтобы он стал I_1), MIDAS (mixed-data sampling) с возможностью добавления разночастотных дополнительных данных, обычные регрессии, различные другие модели машинного обучения, простейшие нейронные сети (в пару слоев с несколькими нейронами), векторные авторегрессии, state-space модели и многие другие.

г. Доверительный интервал прогноза строился на основе ошибки модели. Данный подход занижает ширину доверительного интервала прогноза, однако другие подходы (монте-карло, модельная ошибка на валидации) существенно увеличили бы время отработки проекта.




 
